{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install flair\n",
        "import pandas as pd\n",
        "import flair\n",
        "from textblob import TextBlob\n",
        "import os\n",
        "import datetime\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5NjX7wqOX2-",
        "outputId": "5c7af41e-8c7c-4135-c351-7491920402ac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: flair in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from flair) (2.0.0+cu118)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from flair) (1.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from flair) (0.8.10)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from flair) (6.1.1)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.10/dist-packages (from flair) (1.5.11)\n",
            "Requirement already satisfied: gdown==4.4.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.4.0)\n",
            "Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from flair) (0.3.4)\n",
            "Requirement already satisfied: gensim>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.3.1)\n",
            "Requirement already satisfied: janome in /usr/local/lib/python3.10/dist-packages (from flair) (0.4.2)\n",
            "Requirement already satisfied: transformers[sentencepiece]>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.28.1)\n",
            "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from flair) (0.2.3)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from flair) (1.0.9)\n",
            "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.10/dist-packages (from flair) (0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from flair) (2.8.2)\n",
            "Requirement already satisfied: pptree in /usr/local/lib/python3.10/dist-packages (from flair) (3.1)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.10/dist-packages (from flair) (1.2.13)\n",
            "Requirement already satisfied: conllu>=4.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.5.2)\n",
            "Requirement already satisfied: hyperopt>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from flair) (0.2.7)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from flair) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.65.0)\n",
            "Requirement already satisfied: pytorch-revgrad in /usr/local/lib/python3.10/dist-packages (from flair) (0.2.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from flair) (3.7.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from flair) (9.1.0)\n",
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.10/dist-packages (from flair) (0.5.8)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from flair) (4.9.2)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from flair) (2.1.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from flair) (1.26.130)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from flair) (0.14.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair) (4.11.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair) (3.12.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bpemb>=0.3.2->flair) (0.1.99)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bpemb>=0.3.2->flair) (1.22.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.4->flair) (1.14.1)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim>=3.8.0->flair) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=3.8.0->flair) (6.3.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (2023.4.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (4.5.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (6.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair) (2.2.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair) (3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair) (0.18.3)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair) (0.10.9.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (4.39.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->flair) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->flair) (3.1.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (3.1.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.8,>=1.5.0->flair) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.8,>=1.5.0->flair) (3.25.2)\n",
            "Requirement already satisfied: datasets<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from transformer-smaller-training-vocab>=0.2.1->flair) (2.12.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.18.0->flair) (0.13.3)\n",
            "Requirement already satisfied: protobuf<=3.20.2 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.18.0->flair) (3.20.2)\n",
            "Requirement already satisfied: botocore<1.30.0,>=1.29.130 in /usr/local/lib/python3.10/dist-packages (from boto3->flair) (1.29.130)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->flair) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from boto3->flair) (0.6.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->flair) (0.2.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.130->boto3->flair) (1.26.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (3.8.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (3.2.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (9.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (0.70.14)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (0.18.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (1.5.3)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (0.3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.4.0->flair) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.4.0->flair) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.4.0->flair) (3.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown==4.4.0->flair) (2.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.8,>=1.5.0->flair) (2.1.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.4.0->flair) (1.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.8,>=1.5.0->flair) (1.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (23.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (2022.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDdalsNiNTWX"
      },
      "outputs": [],
      "source": [
        "flair_sentiment = flair.models.TextClassifier.load('en-sentiment')\n",
        "fmt = '%Y-%m-%d %H:00:00'\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "\n",
        "def get_sentiment_val_for_flair(sentiments):\n",
        "    \"\"\"\n",
        "    parse input of the format [NEGATIVE (0.9284018874168396)] and return +ve or -ve float value\n",
        "    :param sentiments:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    print(sentiments)\n",
        "    total_sentiment = str(sentiments)\n",
        "    neg = 'NEGATIVE' in total_sentiment\n",
        "    if neg:\n",
        "        total_sentiment = total_sentiment.replace('NEGATIVE', '')\n",
        "    else:\n",
        "        total_sentiment = total_sentiment.replace('POSITIVE', '')\n",
        "\n",
        "    total_sentiment = total_sentiment.replace('(', '').replace('[', '').replace(')', '').replace(']', '')\n",
        "\n",
        "    words = total_sentiment.split()\n",
        "\n",
        "    score = words[-1]\n",
        "    val = float(score)\n",
        "    if neg:\n",
        "        return -val\n",
        "    return val\n",
        "\n",
        "\n",
        "def get_sentiment_report(input_filename, output_filename):\n",
        "    df = pd.read_csv(input_filename)\n",
        "    df = df[['title', 'selftext', 'publish_date']]\n",
        "    df = df.fillna('')\n",
        "\n",
        "    df['text'] = df['title'] + ' ' + df['selftext']\n",
        "    df.set_index('publish_date', inplace=True)\n",
        "    df.drop(['title', 'selftext'], axis=1, inplace=True)\n",
        "\n",
        "    for row_i, row in df.iterrows():\n",
        "        tb_sentiment_polarity_dict = dict()\n",
        "        tb_sentiment_subjectivity_dict = dict()\n",
        "        flair_sentiment_dict = dict()\n",
        "\n",
        "        sid_pos_dict = dict()\n",
        "        sid_neg_dict = dict()\n",
        "        sid_neu_dict = dict()\n",
        "        sid_com_dict = dict()\n",
        "\n",
        "        data = row['text']\n",
        "        print(row_i)\n",
        "        print(data[0:15])\n",
        "        flair_s = flair.data.Sentence(data)\n",
        "        flair_sentiment.predict(flair_s)\n",
        "        flair_total_sentiment = flair_s.labels\n",
        "        flair_val = get_sentiment_val_for_flair(flair_total_sentiment)\n",
        "\n",
        "        flair_sentiment_dict[str(row_i)] = flair_val\n",
        "        tb_sentiment_polarity_dict[str(row_i)] = TextBlob(data).sentiment[0]\n",
        "        tb_sentiment_subjectivity_dict[str(row_i)] = TextBlob(data).sentiment[1]\n",
        "\n",
        "        ss = sid.polarity_scores(data)\n",
        "        sid_pos_dict[str(row_i)] = ss['pos']\n",
        "        sid_neg_dict[str(row_i)] = ss['neg']\n",
        "        sid_neu_dict[str(row_i)] = ss['neu']\n",
        "        sid_com_dict[str(row_i)] = ss['compound']\n",
        "\n",
        "        flair_df = pd.DataFrame.from_dict(flair_sentiment_dict, orient='index', columns=['reddit_flair'])\n",
        "        flair_df.index.name = 'timestamp'\n",
        "\n",
        "        tb_polarity_df = pd.DataFrame.from_dict(tb_sentiment_polarity_dict, orient='index',\n",
        "                                                columns=['reddit_tb_polarity'])\n",
        "        tb_polarity_df.index.name = 'timestamp'\n",
        "\n",
        "        tb_subjectivity_df = pd.DataFrame.from_dict(tb_sentiment_subjectivity_dict, orient='index',\n",
        "                                                    columns=['reddit_tb_subjectivity'])\n",
        "        tb_subjectivity_df.index.name = 'timestamp'\n",
        "\n",
        "        sid_pos_df = pd.DataFrame.from_dict(sid_pos_dict, orient='index',\n",
        "                                            columns=['reddit_sid_pos'])\n",
        "        sid_pos_df.index.name = 'timestamp'\n",
        "\n",
        "        sid_neg_df = pd.DataFrame.from_dict(sid_neg_dict, orient='index',\n",
        "                                            columns=['reddit_sid_neg'])\n",
        "        sid_neg_df.index.name = 'timestamp'\n",
        "\n",
        "        sid_neu_df = pd.DataFrame.from_dict(sid_neu_dict, orient='index',\n",
        "                                            columns=['reddit_sid_neu'])\n",
        "        sid_neu_df.index.name = 'timestamp'\n",
        "\n",
        "        sid_com_df = pd.DataFrame.from_dict(sid_com_dict, orient='index',\n",
        "                                            columns=['reddit_sid_com'])\n",
        "        sid_com_df.index.name = 'timestamp'\n",
        "\n",
        "        final_senti_df = pd.concat([flair_df, tb_polarity_df, tb_subjectivity_df, sid_pos_df, sid_neg_df, sid_neu_df,\n",
        "        \t\t\t\t\t\t\tsid_com_df], axis=1)\n",
        "\n",
        "        if os.path.exists(output_filename):\n",
        "            keep_header = False\n",
        "        else:\n",
        "            keep_header = True\n",
        "\n",
        "        final_senti_df.to_csv(output_filename, mode='a', header=keep_header)\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "def clean_sentiment_report(input_filename, output_filename):\n",
        "    # drop duplicates and sort\n",
        "    master_df = pd.read_csv(input_filename, index_col=0)\n",
        "    master_df.index = pd.to_datetime(master_df.index)\n",
        "    idx = np.unique(master_df.index, return_index=True)[1]\n",
        "    master_df = master_df.iloc[idx]\n",
        "    master_df.to_csv(output_filename)\n",
        "\n",
        "\n",
        "def bucketize_sentiment_report(input_filename, output_filename):\n",
        "    start_date_time_obj = datetime.datetime(2018, 1, 1, 0)\n",
        "    end_date_time_obj = datetime.datetime(2019, 11, 20, 23)\n",
        "    hr1 = datetime.timedelta(hours=1)\n",
        "    curr_date_time_obj = start_date_time_obj\n",
        "    in_df = pd.read_csv(input_filename)\n",
        "\n",
        "\n",
        "    out_dict = dict()\n",
        "\n",
        "    while curr_date_time_obj <= end_date_time_obj:\n",
        "        curr_timestamp = curr_date_time_obj.strftime(format=fmt)\n",
        "        # print(curr_timestamp)\n",
        "        # create data dict with all possible timestamps and dummy value of reddit_flair\n",
        "        # reddit_flair is chosen just randomly as a placeholder\n",
        "        out_dict[curr_timestamp] = 0\n",
        "        curr_date_time_obj += hr1\n",
        "\n",
        "    out_df = pd.DataFrame.from_dict(out_dict, orient='index',\n",
        "                                    columns=['reddit_flair'])\n",
        "\n",
        "    # print(out_dict)\n",
        "    out_df.index.name = 'timestamp'\n",
        "    # populate more colums\n",
        "    out_df['reddit_flair_count'] = 0\n",
        "    out_df['reddit_tb_polarity'] = 0\n",
        "    out_df['reddit_tb_polarity_count'] = 0\n",
        "    out_df['reddit_tb_subjectivity'] = 0\n",
        "    out_df['reddit_tb_subjectivity_count'] = 0\n",
        "    out_df['reddit_sid_pos'] = 0\n",
        "    out_df['reddit_sid_neg'] = 0\n",
        "    out_df['reddit_sid_neu'] = 0\n",
        "    out_df['reddit_sid_com'] = 0\n",
        "    out_df['reddit_sid_count'] = 0\n",
        "\n",
        "    for i in range(len(in_df)):\n",
        "        timestamp = in_df.loc[i, 'timestamp']\n",
        "        out_key = datetime.datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')\n",
        "        # timestamp is current plus few minutes or seconds, so collect all these data in the bucket of next hour\n",
        "        out_key += hr1\n",
        "        out_key = out_key.strftime(format='%Y-%m-%d %H:00:00')\n",
        "        #print(out_key)\n",
        "        # add up all values and count how many values we have added. In next pass we would normalize the values\n",
        "        try:\n",
        "            out_df.loc[out_key, 'reddit_flair'] += in_df.loc[i, 'reddit_flair']\n",
        "            out_df.loc[out_key, 'reddit_flair_count'] += 1\n",
        "            out_df.loc[out_key, 'reddit_tb_polarity'] += in_df.loc[i, 'reddit_tb_polarity']\n",
        "            out_df.loc[out_key, 'reddit_tb_polarity_count'] += 1\n",
        "            out_df.loc[out_key, 'reddit_tb_subjectivity'] += in_df.loc[i, 'reddit_tb_subjectivity']\n",
        "            out_df.loc[out_key, 'reddit_tb_subjectivity_count'] += 1\n",
        "            out_df.loc[out_key, 'reddit_sid_pos'] += in_df.loc[i, 'reddit_sid_pos']\n",
        "            out_df.loc[out_key, 'reddit_sid_neg'] += in_df.loc[i, 'reddit_sid_neg']\n",
        "            out_df.loc[out_key, 'reddit_sid_neu'] += in_df.loc[i, 'reddit_sid_neu']\n",
        "            out_df.loc[out_key, 'reddit_sid_com'] += in_df.loc[i, 'reddit_sid_com']\n",
        "            out_df.loc[out_key, 'reddit_sid_count'] += 1\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # make timestamp as a column and reindex the dataframe to make loc method happy\n",
        "    out_df['timestamp'] = out_df.index\n",
        "    out_df.index = range(len(out_df))\n",
        "\n",
        "    for i in range(len(out_df)):\n",
        "        #print(out_df.loc[i, 'timestamp'])\n",
        "        # normalize the values\n",
        "        if out_df.loc[i, 'reddit_flair_count'] == 0:\n",
        "            out_df.loc[i, 'reddit_flair'] = 0\n",
        "        else:\n",
        "            out_df.loc[i, 'reddit_flair'] /= out_df.loc[i, 'reddit_flair_count']\n",
        "\n",
        "        if out_df.loc[i, 'reddit_tb_polarity_count'] == 0:\n",
        "            out_df.loc[i, 'reddit_tb_polarity'] = 0\n",
        "        else:\n",
        "            out_df.loc[i, 'reddit_tb_polarity'] /= out_df.loc[i, 'reddit_tb_polarity_count']\n",
        "\n",
        "        if out_df.loc[i, 'reddit_tb_subjectivity_count'] == 0:\n",
        "            out_df.loc[i, 'reddit_tb_subjectivity'] = 0\n",
        "        else:\n",
        "            out_df.loc[i, 'reddit_tb_subjectivity'] /= out_df.loc[i, 'reddit_tb_subjectivity_count']\n",
        "\n",
        "        if out_df.loc[i, 'reddit_sid_count'] == 0:\n",
        "            out_df.loc[i, 'reddit_sid_pos'] = 0\n",
        "            out_df.loc[i, 'reddit_sid_neg'] = 0\n",
        "            out_df.loc[i, 'reddit_sid_neu'] = 0\n",
        "            out_df.loc[i, 'reddit_sid_com'] = 0\n",
        "        else:\n",
        "            out_df.loc[i, 'reddit_sid_pos'] /= out_df.loc[i, 'reddit_sid_count']\n",
        "            out_df.loc[i, 'reddit_sid_neg'] /= out_df.loc[i, 'reddit_sid_count']\n",
        "            out_df.loc[i, 'reddit_sid_neu'] /= out_df.loc[i, 'reddit_sid_count']\n",
        "            out_df.loc[i, 'reddit_sid_com'] /= out_df.loc[i, 'reddit_sid_count']\n",
        "\n",
        "        if os.path.exists(output_filename):\n",
        "            keep_header = False\n",
        "        else:\n",
        "            keep_header = True\n",
        "\n",
        "    out_df.drop(['reddit_flair_count', 'reddit_tb_polarity_count', 'reddit_tb_subjectivity_count','reddit_sid_count'], axis=1,\n",
        "                inplace=True)\n",
        "    # change back index to timestamp to save the data in csv\n",
        "    out_df.set_index('timestamp', inplace=True)\n",
        "    out_df.to_csv(output_filename)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    input_filename = 'reddit_bitcoin_posts.csv'\n",
        "    output_sentiment_filename = input_filename[0:-4] + '_sentiment.csv'\n",
        "\n",
        "    # read input_filename (which can be generated by download_data_from_reddit.py script) and performs\n",
        "    # sentiment analyis of the text data\n",
        "    get_sentiment_report(input_filename, output_sentiment_filename)\n",
        "    output_sentiment_bucketize_filename = output_sentiment_filename[0:-4] + '_bucketized.csv'\n",
        "\n",
        "    # reddit posts can land anytime. Collect all the posts (and its sentiment reports) landed on a given hour (0 to 59 minutes)\n",
        "    # and bucketize them all into the corresponding hour\n",
        "    bucketize_sentiment_report(output_sentiment_filename, output_sentiment_bucketize_filename)"
      ]
    }
  ]
}